{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense # type: ignore\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img # type: ignore\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # type: ignore\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "import google.generativeai as genai\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import textwrap\n",
    "import markdown\n",
    "\n",
    "# Functions and Classes\n",
    "class Gemini:\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        genai.configure(api_key=\"AIzaSyDSLg4jg9epkg2DjqANqymmGfsQXktjEpg\")\n",
    "\n",
    "        self.model = genai.GenerativeModel(\"gemini-pro\")\n",
    "        self.chat = self.model.start_chat(history=[])\n",
    "\n",
    "    def process_user_input(self, user_input):\n",
    "\n",
    "        response = self.chat.send_message(user_input)\n",
    "\n",
    "        text = textwrap.indent(str(response.text).replace(\"â€¢\", \"*\"), \" \", predicate=lambda _: True)\n",
    "\n",
    "        return response.text\n",
    "\n",
    "def roundList(num_list, ndigits=0):\n",
    "    return [round(x, ndigits) for x in num_list]\n",
    "\n",
    "def MultiplyNums(num_list, number):\n",
    "    return [num * number for num in num_list]\n",
    "\n",
    "def process_img(path):\n",
    "    img = load_img(path, target_size=(224, 224))\n",
    "\n",
    "    x = img_to_array(img)\n",
    "    x /= 255.0\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    return x\n",
    "\n",
    "model = tf.keras.models.load_model('osteoarthritisAI7.h5')\n",
    "\n",
    "symptoms = \"ache/pain often very much hurting hip and knee\"\n",
    "\n",
    "picture = process_img(\"./Case 0.png\")\n",
    "\n",
    "gemini = Gemini()\n",
    "\n",
    "chat_response = gemini.process_user_input(f\"can you \\\n",
    "pick out the important stuff from this text of symtoms? \\\n",
    "from the symptoms, can you guess, the disease, \\\n",
    "the treatment and what is important for the doctor \\\n",
    "to know(in doctor terms)?: {symptoms}\")\n",
    "\n",
    "print(f\"AI 1 response: {chat_response}\")\n",
    "\n",
    "# AI 2 \n",
    "case = model.predict(picture).tolist()\n",
    "case = case[0]\n",
    "case = MultiplyNums(case, 100)\n",
    "case = roundList(case, 2)\n",
    "\n",
    "if case[0] > 50:\n",
    "    case_no = 0\n",
    "else:\n",
    "    j = 0\n",
    "    case_no = 0\n",
    "    for i in range(1, len(case)):\n",
    "        if case[i] > j:\n",
    "            j = case[i]\n",
    "            case_no = i\n",
    "\n",
    "# text 3\n",
    "text1 = symptoms\n",
    "text2 = case_no\n",
    "if text2 == 1:\n",
    "    text3 = \"there is a need for NSAID medicine as the pain is consistant\"\n",
    "else:\n",
    "    text3 = \"there are no signs of osteoarthritis, and no osteophytes so, the patient does not have osteoarthritis. \"\n",
    "\n",
    "print(f\"this is Detected As Osteoarthritis KL Grade {text2}. \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries from TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense # type: ignore\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # type: ignore\n",
    "\n",
    "\n",
    "# Data Augmentation and Preprocessing\n",
    "# This section defines two ImageDataGenerator objects for training and testing data.\n",
    "\n",
    "# Train data generator with augmentation techniques\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Rescale pixel values from 0-255 to 0-1 for better training\n",
    "    rotation_range=40,  # Randomly rotate images up to 40 degrees\n",
    "    width_shift_range=0.2,  # Randomly shift images horizontally up to 20% of width\n",
    "    height_shift_range=0.2,  # Randomly shift images vertically up to 20% of height\n",
    "    shear_range=0.2,  # Randomly apply shearing transformation\n",
    "    zoom_range=0.2,  # Randomly zoom images up to 20%\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    fill_mode='nearest'  # How to fill in missing pixels during transformations\n",
    ")\n",
    "\n",
    "# Test data generator with only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# Generate Data Generators\n",
    "# This section uses the ImageDataGenerator objects to create data generators \n",
    "# for training and validation.\n",
    "\n",
    "# Train data generator with labels (categorical for multi-class classification)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/train',  # Path to the training data directory\n",
    "    target_size=(224, 224),  # Resize images to 224x224 pixels\n",
    "    batch_size=32,  # Number of images per batch\n",
    "    class_mode='categorical'  # Categorical labels for multi-class classification (5 classes)\n",
    ")\n",
    "\n",
    "# Validation data generator with labels (categorical)\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'dataset/test',  # Path to the validation data directory\n",
    "    target_size=(224, 224),  # Resize images to 224x224 pixels\n",
    "    batch_size=32,  # Number of images per batch\n",
    "    class_mode='categorical'  # Categorical labels\n",
    ")\n",
    "\n",
    "\n",
    "# Create the Model\n",
    "# This section defines a Sequential model with convolutional, pooling, \n",
    "# flattening, and fully-connected layers.\n",
    "\n",
    "model = Sequential([\n",
    "    # First convolutional layer with 32 filters, 3x3 kernel size, ReLU activation\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    # Max pooling layer with 2x2 pool size for downsampling\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Second convolutional layer with 64 filters, 3x3 kernel size, ReLU activation\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    # Max pooling layer with 2x2 pool size for downsampling\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Third convolutional layer with 128 filters, 3x3 kernel size, ReLU activation\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    # Max pooling layer with 2x2 pool size for downsampling\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Flatten the extracted features from the convolutional layers\n",
    "    Flatten(),\n",
    "\n",
    "    # First fully-connected layer with 128 neurons and ReLU activation\n",
    "    Dense(128, activation='relu'),\n",
    "\n",
    "    # Output layer with 5 neurons (assuming 5 classes) and softmax activation\n",
    "    # Softmax activation outputs probabilities for each class\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the Model\n",
    "# This section defines the optimizer, loss function, and metrics for training.\n",
    "\n",
    "model.compile(optimizer='adam',  # Adam optimizer for gradient descent\n",
    "              loss='categorical_crossentropy',  # Categorical crossentropy loss for multi-class classification\n",
    "              metrics=['accuracy'])  # Track accuracy during training\n",
    "\n",
    "\n",
    "# Train the Model\n",
    "# This section trains the model on the training data generator for 10 epochs\n",
    "# and validates on the validation data generator.\n",
    "\n",
    "# Train the model\n",
    "num_epochs_per_save = 10\n",
    "num_saves = 10\n",
    "\n",
    "for i in range(num_saves):\n",
    "\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        epochs=num_epochs_per_save,\n",
    "        validation_data=validation_generator\n",
    "    )\n",
    "\n",
    "    # Save the model after each set of epochs\n",
    "    model.save(f\"osteoarthritisAI{i+1}.h5\")\n",
    "\n",
    "gemini = Gemini()\n",
    "\n",
    "chat_response = gemini.process_user_input(f\"can you pick out the important stuff from this text of symtoms? from the symptoms, can you guess, the disease, \\\n",
    " the treatment and what is important for the doctor to know(in doctor terms)?: {symptoms}\")\n",
    "\n",
    "print(f\"AI 1 Response: {chat_response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
